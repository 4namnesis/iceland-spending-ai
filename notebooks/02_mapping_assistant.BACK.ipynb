{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "699aca0c",
   "metadata": {},
   "source": [
    "# 02 Mapping Assistant\n",
    "\n",
    "Interactive tool for reviewing **unmapped ministries/categories** and assigning them to normalized categories.\n",
    "\n",
    "### How it works:\n",
    "1. Loads `data/unmapped_categories.csv` (newly discovered ministries)\n",
    "2. Loads `data/mappings_cleaned.csv` (current mapping table)\n",
    "3. Displays unmapped ministries and lets you assign normalized categories interactively\n",
    "4. Saves results back to `mappings_cleaned.csv` **with backups**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78a84a6f-c93e-4515-8f1c-b4f43afdb946",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6cd6f78583d4fbaa5691b1d3d3daf81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntProgress(value=0, bar_style='info', description='Processing:', max=39), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SUMMARY OF MISSING MAPPINGS ===\n",
      "  ‚Ä¢ 2004rikisreikningurheild_parsed.csv: 38 missing\n",
      "  ‚Ä¢ 2007Rikisreikn_Heildaryfirlit_parsed.csv: 7 missing\n",
      "  ‚Ä¢ 2007Rikisreikn_arsreikningur_rikisadila_parsed.csv: 44 missing\n",
      "  ‚Ä¢ 2012-RR-rikisadila_parsed.csv: 44 missing\n",
      "  ‚Ä¢ RR-2005-heild_parsed.csv: 6 missing\n",
      "  ‚Ä¢ RR-2008-R_parsed.csv: 6 missing\n",
      "  ‚Ä¢ RR-2008-arsreikningurrikisadila_parsed.csv: 40 missing\n",
      "  ‚Ä¢ RR2006_arsreikningur_rikisadila_parsed.csv: 43 missing\n",
      "  ‚Ä¢ RRheild2000_parsed.csv: 35 missing\n",
      "  ‚Ä¢ RRheild_2006-A_parsed.csv: 5 missing\n",
      "  ‚Ä¢ Rikisr-05-S_parsed.csv: 30 missing\n",
      "  ‚Ä¢ Rikisreikn-01_parsed.csv: 35 missing\n",
      "  ‚Ä¢ Rikisreikn-02_parsed.csv: 34 missing\n",
      "  ‚Ä¢ Rikisreikn-03_parsed.csv: 34 missing\n",
      "  ‚Ä¢ Rikisreikn2009ArsreiknRikisadila_parsed.csv: 44 missing\n",
      "  ‚Ä¢ Rikisreikn2009Heildaryfirlit_parsed.csv: 7 missing\n",
      "  ‚Ä¢ Rikisreikningur-2011-arsreikningar-rikiisadila_parsed.csv: 42 missing\n",
      "  ‚Ä¢ Rikisreikningur-2016-Arsreikningur-Rikisadila_parsed.csv: 38 missing\n",
      "  ‚Ä¢ Rikisreikningur-2019_parsed.csv: 55 missing\n",
      "  ‚Ä¢ Rikisreikningur-2020_parsed.csv: 55 missing\n",
      "  ‚Ä¢ Rikisreikningur-arid-2013,-Heildaryfirlit---Rafraen-undirritun_parsed.csv: 6 missing\n",
      "  ‚Ä¢ Rikisreikningur-arid-2013-Arsreikningur-Rikisadila_parsed.csv: 43 missing\n",
      "  ‚Ä¢ Rikisreikningur-arid-2014-Arsreikningar-rikisadila_parsed.csv: 41 missing\n",
      "  ‚Ä¢ Rikisreikningur-arid-2014-Heildaryfirlit-Rafraenundirritun_parsed.csv: 7 missing\n",
      "  ‚Ä¢ Rikisreikningur-arid-2015-Arsreikningar-rikisadila_parsed.csv: 38 missing\n",
      "  ‚Ä¢ Rikisreikningur-arid-2015-Heildaryfirlit_parsed.csv: 7 missing\n",
      "  ‚Ä¢ Rikisreikningur-arid-2016--Heildaryfirlit_parsed.csv: 6 missing\n",
      "  ‚Ä¢ Rikisreikningur-heildaryfirlit-2011_parsed.csv: 6 missing\n",
      "  ‚Ä¢ Rikisreikningur_04072019_parsed.csv: 131 missing\n",
      "  ‚Ä¢ Rikisreikningur_11102018_FJS_parsed.csv: 118 missing\n",
      "  ‚Ä¢ Rikisreikningur_2010rikisadila_parsed.csv: 44 missing\n",
      "  ‚Ä¢ Rikisreikningur_Heildaryfirlit_2010_parsed.csv: 8 missing\n",
      "  ‚Ä¢ all_years_parsed.csv: 1107 missing\n",
      "  ‚Ä¢ fb_210803_parsed.csv: 1 missing\n",
      "  ‚Ä¢ fb_300904_ahj_parsed.csv: 1 missing\n",
      "  ‚Ä¢ rikisreikningur2012_parsed.csv: 8 missing\n",
      "\n",
      "‚ö†Ô∏è Missing categories saved to: /home/ampersand/iceland-spending-ai/data/unmapped_after_propagation.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "root = Path('/home/ampersand/iceland-spending-ai')\n",
    "data_dir = root / 'data'\n",
    "structured_dir = data_dir / 'structured_csvs'\n",
    "normalized_dir = data_dir / 'normalized'\n",
    "mappings_file = data_dir / 'mappings_cleaned.csv'\n",
    "unmapped_output = data_dir / 'unmapped_after_propagation.csv'\n",
    "unmapped_path = data_dir / 'unmapped_categories.csv'\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from ipywidgets import IntProgress, HTML, VBox\n",
    "from IPython.display import display\n",
    "\n",
    "# === PATH SETUP ===\n",
    "root = Path('/home/ampersand/iceland-spending-ai')\n",
    "\n",
    "normalized_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not mappings_file.exists():\n",
    "    raise FileNotFoundError(f\"‚ùå Missing mappings file: {mappings_file}\")\n",
    "\n",
    "# === LOAD MAPPINGS ===\n",
    "mappings_df = pd.read_csv(mappings_file)\n",
    "mappings_df['Ministry'] = mappings_df['Ministry'].astype(str).str.strip()\n",
    "mappings_df['Category'] = mappings_df['Category'].astype(str).str.strip()\n",
    "mapping_dict = dict(zip(mappings_df['Ministry'], mappings_df['Category']))\n",
    "\n",
    "# === PROCESS STRUCTURED CSV FILES ===\n",
    "csv_files = sorted([f for f in structured_dir.glob(\"*.csv\")])\n",
    "progress = IntProgress(min=0, max=len(csv_files), description=\"Processing:\", bar_style='info')\n",
    "status = HTML()\n",
    "display(VBox([progress, status]))\n",
    "\n",
    "missing_counts = {}\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    if \"Ministry\" not in df.columns:\n",
    "        continue\n",
    "\n",
    "    # Apply mappings\n",
    "    df['normalized_category'] = df['Ministry'].map(mapping_dict)\n",
    "    missing_mask = df['normalized_category'].isna()\n",
    "\n",
    "    # Store count + actual ministries\n",
    "    missing_ministries = sorted(df.loc[missing_mask, 'Ministry'].dropna().unique().tolist())\n",
    "    missing_counts[csv_file.name] = {\n",
    "        \"count\": missing_mask.sum(),\n",
    "        \"ministries\": missing_ministries\n",
    "    }\n",
    "\n",
    "    # Fill missing with placeholder\n",
    "    df['normalized_category'] = df['normalized_category'].fillna(\"Misc/Missing\")\n",
    "\n",
    "    # Save normalized file\n",
    "    out_path = normalized_dir / csv_file.name.replace(\".csv\", \"_normalized.csv\")\n",
    "    df.to_csv(out_path, index=False)\n",
    "\n",
    "    # Update progress bar\n",
    "    progress.value += 1\n",
    "    status.value = f\"<b>{csv_file.name}</b>: {len(df)} rows ‚Üí {missing_mask.sum()} missing\"\n",
    "\n",
    "progress.bar_style = \"success\"\n",
    "status.value = \"<b>‚úÖ All files processed.</b>\"\n",
    "\n",
    "# === REPORT MISSING MAPPINGS ===\n",
    "missing_summary = {f: m for f, m in missing_counts.items() if m[\"count\"] > 0}\n",
    "\n",
    "if missing_summary:\n",
    "    # Save CSV with counts + examples\n",
    "    missing_df = pd.DataFrame([\n",
    "        {\n",
    "            \"File\": fname,\n",
    "            \"Missing_Count\": info[\"count\"],\n",
    "            \"Example_Unmapped\": \", \".join(info[\"ministries\"][:5])\n",
    "        }\n",
    "        for fname, info in missing_summary.items()\n",
    "    ])\n",
    "    missing_df.to_csv(unmapped_output, index=False)\n",
    "\n",
    "    print(\"\\n=== SUMMARY OF MISSING MAPPINGS ===\")\n",
    "    for fname, info in missing_summary.items():\n",
    "        print(f\"  ‚Ä¢ {fname}: {info['count']} missing\")\n",
    "        if info[\"ministries\"]:\n",
    "            print(f\"      ‚Ü≥ Examples: {', '.join(info['ministries'][:3])}\")\n",
    "    print(f\"\\n‚ö†Ô∏è Missing categories saved to: {unmapped_output}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All ministries mapped successfully. No unmapped categories remain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c769bf2-fbf1-4267-afe3-bd227ae8535c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a14848f7-4503-4685-9d2e-834cab34d0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56059e1ae08544949bea63950baf6e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='File:', layout=Layout(width='600px'), options=('-- Select CSV file --', '‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "\n",
    "# === Load mappings and categories ===\n",
    "mappings_path = mappings_file\n",
    "mappings_df = pd.read_csv(mappings_path)\n",
    "mappings_df[\"Ministry\"] = mappings_df[\"Ministry\"].astype(str).str.strip()\n",
    "mappings_df[\"Category\"] = mappings_df[\"Category\"].astype(str).str.strip()\n",
    "\n",
    "all_categories = sorted(mappings_df[\"Category\"].unique())\n",
    "\n",
    "# === Widgets ===\n",
    "file_dropdown = widgets.Dropdown(\n",
    "    options=[\"-- Select CSV file --\"] + list(missing_summary.keys()),\n",
    "    description=\"File:\",\n",
    "    layout=widgets.Layout(width=\"600px\")\n",
    ")\n",
    "\n",
    "ministry_dropdown = widgets.Dropdown(\n",
    "    options=[\"-- Select ministry --\"],\n",
    "    description=\"Ministry:\",\n",
    "    layout=widgets.Layout(width=\"600px\")\n",
    ")\n",
    "\n",
    "category_dropdown = widgets.Dropdown(\n",
    "    options=[\"-- Select existing category --\"] + all_categories,\n",
    "    description=\"Category:\",\n",
    "    layout=widgets.Layout(width=\"600px\")\n",
    ")\n",
    "\n",
    "new_category_box = widgets.Text(\n",
    "    placeholder=\"Or type a NEW category\",\n",
    "    description=\"New Cat:\",\n",
    "    layout=widgets.Layout(width=\"600px\")\n",
    ")\n",
    "\n",
    "save_button = widgets.Button(\n",
    "    description=\"üíæ Save Mapping & Update\",\n",
    "    button_style=\"success\",\n",
    "    layout=widgets.Layout(width=\"300px\")\n",
    ")\n",
    "\n",
    "status_output = widgets.Output()\n",
    "\n",
    "# === Step 1. Load unmapped ministries for a file ===\n",
    "def on_file_select(change):\n",
    "    ministry_dropdown.options = [\"-- Select ministry --\"]\n",
    "    if change[\"new\"] == \"-- Select CSV file --\":\n",
    "        return\n",
    "\n",
    "    file_path = structured_dir / change[\"new\"]\n",
    "    if not file_path.exists():\n",
    "        with status_output:\n",
    "            clear_output()\n",
    "            print(f\"‚ö†Ô∏è File not found: {file_path}\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    if \"Ministry\" not in df.columns:\n",
    "        with status_output:\n",
    "            clear_output()\n",
    "            print(f\"‚ö†Ô∏è No Ministry column in {change['new']}\")\n",
    "        return\n",
    "\n",
    "    unmapped = sorted(set(df[\"Ministry\"].dropna()) - set(mappings_df[\"Ministry\"]))\n",
    "    ministry_dropdown.options = [\"-- Select ministry --\"] + unmapped\n",
    "\n",
    "file_dropdown.observe(on_file_select, names=\"value\")\n",
    "\n",
    "# === Step 2. Save mapping ===\n",
    "def on_save_clicked(_):\n",
    "    selected_file = file_dropdown.value\n",
    "    selected_ministry = ministry_dropdown.value\n",
    "\n",
    "    if selected_file == \"-- Select CSV file --\" or selected_ministry == \"-- Select ministry --\":\n",
    "        with status_output:\n",
    "            clear_output()\n",
    "            print(\"‚ö†Ô∏è Please select both a CSV and a ministry.\")\n",
    "        return\n",
    "\n",
    "    # Determine category (either dropdown or new)\n",
    "    category = new_category_box.value.strip() or (\n",
    "        category_dropdown.value if category_dropdown.value != \"-- Select existing category --\" else None\n",
    "    )\n",
    "\n",
    "    if not category:\n",
    "        with status_output:\n",
    "            clear_output()\n",
    "            print(\"‚ö†Ô∏è Please select or enter a category.\")\n",
    "        return\n",
    "\n",
    "    # Update mappings DataFrame\n",
    "    new_row = pd.DataFrame({\"Ministry\": [selected_ministry], \"Category\": [category]})\n",
    "    mappings_df_updated = pd.concat([mappings_df, new_row], ignore_index=True)\n",
    "    mappings_df_updated.drop_duplicates(subset=\"Ministry\", keep=\"last\", inplace=True)\n",
    "    mappings_df_updated.to_csv(mappings_path, index=False)\n",
    "\n",
    "    # Re-run normalization ONLY for this file\n",
    "    df = pd.read_csv(structured_dir / selected_file)\n",
    "    df[\"normalized_category\"] = df[\"Ministry\"].map(\n",
    "        dict(zip(mappings_df_updated[\"Ministry\"], mappings_df_updated[\"Category\"]))\n",
    "    )\n",
    "    df[\"normalized_category\"].fillna(\"Misc/Missing\", inplace=True)\n",
    "    out_path = normalized_dir / selected_file.replace(\".csv\", \"_normalized.csv\")\n",
    "    df.to_csv(out_path, index=False)\n",
    "\n",
    "    # Update available categories live\n",
    "    category_dropdown.options = [\"-- Select existing category --\"] + sorted(\n",
    "        mappings_df_updated[\"Category\"].unique()\n",
    "    )\n",
    "\n",
    "    with status_output:\n",
    "        clear_output()\n",
    "        print(f\"‚úÖ Saved mapping: '{selected_ministry}' ‚Üí '{category}'\")\n",
    "        print(f\"üîÑ Normalized file updated: {out_path}\")\n",
    "\n",
    "save_button.on_click(on_save_clicked)\n",
    "\n",
    "# === Display UI ===\n",
    "display(widgets.VBox([\n",
    "    file_dropdown,\n",
    "    ministry_dropdown,\n",
    "    category_dropdown,\n",
    "    new_category_box,\n",
    "    save_button,\n",
    "    status_output\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bb785af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loaded 4283 unmapped entries.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unmapped_Ministry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(√Åri√∞ 2007: F√©lagsm√°lar√°√∞uneyti, Skuldir og ei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- 01 101 Fors√¶tisr√°√∞uneyti, a√∞alskrifstofa -7.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>- 03 101 Utanr√≠kisr√°√∞uneyti, a√∞alskrifstofa -3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44.100 ‚Äî 40 101 Samg√∂ngur√°√∞uneyti, a√∞alskrifs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2% fr√° √°rinu √° undan. Gj√∂ld r√°√∞uneytisins n√°mu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Unmapped_Ministry\n",
       "0  (√Åri√∞ 2007: F√©lagsm√°lar√°√∞uneyti, Skuldir og ei...\n",
       "1  - 01 101 Fors√¶tisr√°√∞uneyti, a√∞alskrifstofa -7.102\n",
       "2  - 03 101 Utanr√≠kisr√°√∞uneyti, a√∞alskrifstofa -3...\n",
       "3  -44.100 ‚Äî 40 101 Samg√∂ngur√°√∞uneyti, a√∞alskrifs...\n",
       "4   0.2% fr√° √°rinu √° undan. Gj√∂ld r√°√∞uneytisins n√°mu"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "root = Path('/home/ampersand/iceland-spending-ai')\n",
    "mappings_path = data_dir / \"mappings_cleaned.csv\"\n",
    "\n",
    "\n",
    "if not unmapped_path.exists():\n",
    "    raise FileNotFoundError(f\"Missing file: {unmapped_path}\")\n",
    "if not mappings_path.exists():\n",
    "    raise FileNotFoundError(f\"Missing file: {mappings_path}\")\n",
    "\n",
    "unmapped_df = pd.read_csv(unmapped_path)\n",
    "mappings_df = pd.read_csv(mappings_path)\n",
    "\n",
    "\n",
    "print(f\"üì• Loaded {len(unmapped_df)} unmapped entries.\")\n",
    "display(unmapped_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb1adf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Ministries requiring attention: 0\n"
     ]
    }
   ],
   "source": [
    "from ipywidgets import IntProgress, HTML, VBox\n",
    "\n",
    "# Get existing categories and already-mapped ministries\n",
    "existing_categories = sorted(mappings_df['Category'].dropna().unique())\n",
    "already_mapped = set(mappings_df['Ministry'].dropna().str.strip())\n",
    "\n",
    "# Ministries still missing normalized categories\n",
    "missing_normalized = set()\n",
    "for fname in sorted(os.listdir(structured_dir)):\n",
    "    if not fname.endswith(\".csv\"):\n",
    "        continue\n",
    "    path = os.path.join(structured_dir, fname)\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "    except:\n",
    "        continue\n",
    "    # If normalized_category column exists, find missing\n",
    "    if \"normalized_category\" in df.columns:\n",
    "        missing = df[df[\"normalized_category\"].isna()]\n",
    "        if not missing.empty and \"Ministry\" in missing.columns:\n",
    "            missing_normalized.update(\n",
    "                missing[\"Ministry\"].dropna().astype(str).str.strip().unique()\n",
    "            )\n",
    "\n",
    "# Combine unmapped + missing-normalized\n",
    "combined_unmapped = set(unmapped_df['Unmapped_Ministry'].dropna().str.strip())\n",
    "unmapped_list = sorted((combined_unmapped | missing_normalized) - already_mapped)\n",
    "\n",
    "# Filter out garbage entries\n",
    "filtered_unmapped_list = [\n",
    "    m for m in unmapped_list\n",
    "    if isinstance(m, str)\n",
    "    and m.strip()\n",
    "    and not m.strip().replace(\".\", \"\").replace(\"-\", \"\").isdigit()\n",
    "]\n",
    "\n",
    "print(f\"üìå Ministries requiring attention: {len(filtered_unmapped_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dca05ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d090bc78b0694c908ca1114f692046db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntProgress(value=0, description='Progress:', max=0), HTML(value='<b>0 / 0 mapped (0%)</b>')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ All ministries mapped!\n",
      "‚ö†Ô∏è No new mappings to save.\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "import pandas as pd\n",
    "from ipywidgets import interact, Dropdown, Button, VBox, HBox, HTML, IntProgress\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "assignments = {}\n",
    "total = len(filtered_unmapped_list)\n",
    "\n",
    "# --- Progress bar UI ---\n",
    "progress_bar = IntProgress(value=0, min=0, max=total, description=\"Progress:\")\n",
    "progress_label = HTML(f\"<b>0 / {total} mapped (0%)</b>\")\n",
    "progress_box = VBox([progress_bar, progress_label])\n",
    "display(progress_box)\n",
    "\n",
    "def suggest_category(ministry):\n",
    "    \"\"\"Suggest the closest existing category for a given ministry.\"\"\"\n",
    "    matches = difflib.get_close_matches(ministry, existing_categories, n=1, cutoff=0.6)\n",
    "    return matches[0] if matches else \"Misc/Missing\"\n",
    "\n",
    "def update_progress():\n",
    "    done = len(assignments)\n",
    "    pct = (done / total) * 100 if total else 100\n",
    "    progress_bar.value = done\n",
    "    progress_label.value = f\"<b>{done} / {total} mapped ({pct:.1f}%)</b>\"\n",
    "\n",
    "def map_next(index=0):\n",
    "    if index >= total:\n",
    "        print(\"üéâ All ministries mapped!\")\n",
    "        finalize_mappings()\n",
    "        return\n",
    "    \n",
    "    ministry = filtered_unmapped_list[index]\n",
    "    default_category = suggest_category(ministry)\n",
    "    \n",
    "    # Dropdown for manual override\n",
    "    dropdown = Dropdown(\n",
    "        options=existing_categories + [\"Misc/Missing\"],\n",
    "        value=default_category,\n",
    "        description=\"Category:\"\n",
    "    )\n",
    "    \n",
    "    confirm_btn = Button(description=\"Confirm\", button_style=\"success\")\n",
    "    skip_btn = Button(description=\"Skip\", button_style=\"warning\")\n",
    "    info = HTML(f\"<b>Ministry:</b> {ministry}\")\n",
    "    \n",
    "    def confirm(_):\n",
    "        assignments[ministry] = dropdown.value\n",
    "        update_progress()\n",
    "        box.close()\n",
    "        map_next(index + 1)\n",
    "        \n",
    "    def skip(_):\n",
    "        assignments[ministry] = \"Misc/Missing\"\n",
    "        update_progress()\n",
    "        box.close()\n",
    "        map_next(index + 1)\n",
    "    \n",
    "    confirm_btn.on_click(confirm)\n",
    "    skip_btn.on_click(skip)\n",
    "    \n",
    "    box = VBox([info, dropdown, HBox([confirm_btn, skip_btn])])\n",
    "    display(box)\n",
    "\n",
    "def finalize_mappings():\n",
    "    \"\"\"Automatically append new mappings into mappings_cleaned.csv and save backup.\"\"\"\n",
    "    if not assignments:\n",
    "        print(\"‚ö†Ô∏è No new mappings to save.\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # Save a backup before modifying\n",
    "    if os.path.exists(mapping_path):\n",
    "        os.rename(mapping_path, backup_path)\n",
    "        print(f\"üóÑ Backup saved: {backup_path}\")\n",
    "    \n",
    "    # Load existing mappings if available\n",
    "    try:\n",
    "        df_existing = pd.read_csv(backup_path)\n",
    "    except FileNotFoundError:\n",
    "        df_existing = pd.DataFrame(columns=[\"LineCode\", \"Ministry\", \"Category\"])\n",
    "    \n",
    "    # Prepare new mappings DataFrame\n",
    "    df_new = pd.DataFrame(\n",
    "        [(None, m, c) for m, c in assignments.items()],\n",
    "        columns=[\"LineCode\", \"Ministry\", \"Category\"]\n",
    "    )\n",
    "    \n",
    "    # Merge old + new and drop duplicates\n",
    "    df_updated = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "    df_updated = df_updated.drop_duplicates(subset=[\"Ministry\"], keep=\"last\")\n",
    "    \n",
    "    # Save updated mapping file\n",
    "    df_updated.to_csv(mapping_path, index=False)\n",
    "    print(f\"‚úÖ Updated mappings saved to: {mapping_path}\")\n",
    "    print(f\"‚ûï Added {len(df_new)} new mappings.\")\n",
    "\n",
    "# Start mapping process\n",
    "map_next(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90df8e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f50d611284425ab5c2e05ea008b3b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='üíæ Save & Backup', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import shutil\n",
    "from ipywidgets import Button\n",
    "\n",
    "# Ensure backups directory exists\n",
    "backup_dir = os.path.join(os.path.dirname(mappings_path), \"backups\")\n",
    "os.makedirs(backup_dir, exist_ok=True)\n",
    "\n",
    "def save_assignments(_):\n",
    "    global mappings_df\n",
    "    if not assignments:\n",
    "        print(\"‚ö†Ô∏è No new assignments to save.\")\n",
    "        return\n",
    "\n",
    "    # Add new mappings to dataframe\n",
    "    new_rows = pd.DataFrame({\n",
    "        \"LineCode\": [None] * len(assignments),\n",
    "        \"Ministry\": list(assignments.keys()),\n",
    "        \"Category\": list(assignments.values())\n",
    "    })\n",
    "    mappings_df = pd.concat([mappings_df, new_rows], ignore_index=True)\n",
    "\n",
    "    # Backup old mappings_cleaned.csv\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    backup_path = os.path.join(backup_dir, f\"mappings_cleaned_backup_{timestamp}.csv\")\n",
    "    shutil.copy(mappings_path, backup_path)\n",
    "\n",
    "    # Save updated mappings_cleaned.csv\n",
    "    mappings_df.to_csv(mappings_path, index=False)\n",
    "\n",
    "    print(f\"üíæ Saved {len(assignments)} new mappings.\")\n",
    "    print(f\"üìÇ Updated: {mappings_path}\")\n",
    "    print(f\"üì¶ Backup created: {backup_path}\")\n",
    "\n",
    "# Add a save button\n",
    "save_button = Button(description=\"üíæ Save & Backup\", button_style=\"success\")\n",
    "save_button.on_click(save_assignments)\n",
    "display(save_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a99f195c-7d2a-45a0-bc1a-03d9b81406e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4283, 1)\n",
      "                                   Unmapped_Ministry\n",
      "0  (√Åri√∞ 2007: F√©lagsm√°lar√°√∞uneyti, Skuldir og ei...\n",
      "1  - 01 101 Fors√¶tisr√°√∞uneyti, a√∞alskrifstofa -7.102\n",
      "2  - 03 101 Utanr√≠kisr√°√∞uneyti, a√∞alskrifstofa -3...\n",
      "3  -44.100 ‚Äî 40 101 Samg√∂ngur√°√∞uneyti, a√∞alskrifs...\n",
      "4   0.2% fr√° √°rinu √° undan. Gj√∂ld r√°√∞uneytisins n√°mu\n",
      "5  00 201 Al√æingi 43.500 02 101 Menntam√°lar√°√∞uney...\n",
      "6  00 401 H√¶stir√©ttu 7600 09101 Fj√°rm√°lar√°√∞uneyti...\n",
      "7  00 √Ü√∞sta stj√≥rn r√≠kisins 18.000 02 Mennta- og ...\n",
      "8  00213 Aldarafm√¶li sj√°lfst√¶√∞is og fullveldis √çs...\n",
      "9  00213 Aldarafm√¶li sj√°lfst√¶√∞is r√°√∞uneyti, a√∞als...\n"
     ]
    }
   ],
   "source": [
    "print(unmapped_df.shape)\n",
    "print(unmapped_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54ec27aa-40f6-4476-bd3e-e7a2465c1ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Missing normalized categories found:\n",
      "  ‚Ä¢ Rikisreikn2009Heildaryfirlit_parsed_normalized.csv: 5746 missing\n",
      "  ‚Ä¢ Rikisreikn2009ArsreiknRikisadila_parsed_normalized.csv: 17401 missing\n",
      "  ‚Ä¢ Rikisreikningur-arid-2014-Arsreikningar-rikisadila_parsed_clean.csv: 16421 missing\n",
      "  ‚Ä¢ 2007Rikisreikn_Heildaryfirlit_parsed_clean.csv: 5302 missing\n",
      "  ‚Ä¢ RRheild2000_parsed_clean.csv: 2915 missing\n",
      "  ‚Ä¢ Rikisreikn-03_parsed_clean.csv: 4995 missing\n",
      "  ‚Ä¢ rikisreikningur2012_parsed_normalized.csv: 5563 missing\n",
      "  ‚Ä¢ 2004rikisreikningurheild_clean.csv: 26 missing\n",
      "  ‚Ä¢ Rikisreikningur-arid-2015-Arsreikningar-rikisadila_parsed_clean.csv: 16791 missing\n",
      "  ‚Ä¢ Rikisreikn2009ArsreiknRikisadila_parsed_clean.csv: 17401 missing\n",
      "  ‚Ä¢ 2012-RR-rikisadila_parsed_normalized.csv: 16718 missing\n",
      "  ‚Ä¢ all_years_parsed_clean.csv: 325780 missing\n",
      "  ‚Ä¢ Rikisreikningur-arid-2015-Heildaryfirlit_parsed_normalized.csv: 6255 missing\n",
      "  ‚Ä¢ Rikisreikningur_11102018_FJS_parsed_normalized.csv: 4022 missing\n",
      "  ‚Ä¢ fb_210803_parsed_normalized.csv: 53 missing\n",
      "  ‚Ä¢ Rikisreikningur_11102018_FJS_parsed_clean.csv: 4022 missing\n",
      "  ‚Ä¢ Rikisreikningur_Heildaryfirlit_2010_parsed_clean.csv: 5318 missing\n",
      "  ‚Ä¢ 2004rikisreikningurheild_normalized.csv: 26 missing\n",
      "  ‚Ä¢ Rikisreikn-01_parsed_clean.csv: 4882 missing\n",
      "  ‚Ä¢ Rikisreikningur-arid-2014-Heildaryfirlit-Rafraenundirritun_parsed_clean.csv: 6347 missing\n",
      "  ‚Ä¢ Rikisreikn-03_parsed_normalized.csv: 4995 missing\n",
      "  ‚Ä¢ Rikisreikningur-2016-Arsreikningur-Rikisadila_parsed_normalized.csv: 15100 missing\n",
      "  ‚Ä¢ 2012-RR-rikisadila_parsed_clean.csv: 16718 missing\n",
      "  ‚Ä¢ Rikisreikningur_Heildaryfirlit_2010_parsed_normalized.csv: 5318 missing\n",
      "  ‚Ä¢ RR-2005-heild_parsed_normalized.csv: 5324 missing\n",
      "  ‚Ä¢ Rikisreikningur_04072019_parsed_normalized.csv: 5720 missing\n",
      "  ‚Ä¢ RR2006_arsreikningur_rikisadila_parsed_normalized.csv: 19154 missing\n",
      "  ‚Ä¢ Rikisreikningur-2020_parsed_clean.csv: 7119 missing\n",
      "  ‚Ä¢ Rikisreikningur-heildaryfirlit-2011_parsed_normalized.csv: 5753 missing\n",
      "  ‚Ä¢ Rikisreikningur-2016-Arsreikningur-Rikisadila_parsed_clean.csv: 15100 missing\n",
      "  ‚Ä¢ 2007Rikisreikn_arsreikningur_rikisadila_parsed_clean.csv: 19170 missing\n",
      "  ‚Ä¢ RRheild_2006-A_parsed_clean.csv: 5196 missing\n",
      "  ‚Ä¢ Rikisreikn2009Heildaryfirlit_parsed_clean.csv: 5746 missing\n",
      "  ‚Ä¢ RR-2008-arsreikningurrikisadila_parsed_clean.csv: 18451 missing\n",
      "  ‚Ä¢ RRheild2000_parsed_normalized.csv: 2915 missing\n",
      "  ‚Ä¢ RR-2008-R_parsed_normalized.csv: 5424 missing\n",
      "  ‚Ä¢ Rikisr-05-S_parsed_normalized.csv: 19835 missing\n",
      "  ‚Ä¢ Rikisreikningur_2010rikisadila_parsed_normalized.csv: 17728 missing\n",
      "  ‚Ä¢ Rikisreikningur-arid-2015-Heildaryfirlit_parsed_clean.csv: 6255 missing\n",
      "  ‚Ä¢ RRheild_2006-A_parsed_normalized.csv: 5196 missing\n",
      "  ‚Ä¢ Rikisreikningur_2010rikisadila_parsed_clean.csv: 17728 missing\n",
      "  ‚Ä¢ Rikisreikningur-arid-2014-Heildaryfirlit-Rafraenundirritun_parsed_normalized.csv: 6347 missing\n",
      "  ‚Ä¢ 2007Rikisreikn_Heildaryfirlit_clean.csv: 25 missing\n",
      "  ‚Ä¢ RR-2005-heild_parsed_clean.csv: 5324 missing\n",
      "  ‚Ä¢ Rikisreikningur_04072019_parsed_clean.csv: 5720 missing\n",
      "  ‚Ä¢ 2007Rikisreikn_arsreikningur_rikisadila_parsed_normalized.csv: 19170 missing\n",
      "  ‚Ä¢ 2004rikisreikningurheild_parsed_normalized.csv: 4726 missing\n",
      "  ‚Ä¢ 2007Rikisreikn_Heildaryfirlit_parsed_normalized.csv: 5302 missing\n",
      "  ‚Ä¢ Rikisreikningur-arid-2014-Arsreikningar-rikisadila_parsed_normalized.csv: 16421 missing\n",
      "  ‚Ä¢ Rikisreikningur-2011-arsreikningar-rikiisadila_parsed_clean.csv: 17325 missing\n",
      "  ‚Ä¢ Rikisreikningur-2020_parsed_normalized.csv: 7119 missing\n",
      "  ‚Ä¢ Rikisr-05-S_parsed_clean.csv: 19835 missing\n",
      "  ‚Ä¢ fb_300904_ahj_parsed_normalized.csv: 32 missing\n",
      "  ‚Ä¢ Rikisreikningur-arid-2016--Heildaryfirlit_parsed_normalized.csv: 5840 missing\n",
      "  ‚Ä¢ 2007Rikisreikn_Heildaryfirlit_normalized.csv: 25 missing\n",
      "  ‚Ä¢ RR-2008-arsreikningurrikisadila_parsed_normalized.csv: 18451 missing\n",
      "  ‚Ä¢ Rikisreikningur-arid-2016--Heildaryfirlit_parsed_clean.csv: 5840 missing\n",
      "  ‚Ä¢ fb_210803_parsed_clean.csv: 53 missing\n",
      "  ‚Ä¢ Rikisreikningur-2019_parsed_clean.csv: 6898 missing\n",
      "  ‚Ä¢ Rikisreikn-01_parsed_normalized.csv: 4882 missing\n",
      "  ‚Ä¢ Rikisreikn-02_parsed_clean.csv: 4979 missing\n",
      "  ‚Ä¢ Rikisreikningur-heildaryfirlit-2011_parsed_clean.csv: 5753 missing\n",
      "  ‚Ä¢ RR2006_arsreikningur_rikisadila_parsed_clean.csv: 19154 missing\n",
      "  ‚Ä¢ Rikisreikningur-arid-2013-Arsreikningur-Rikisadila_parsed_normalized.csv: 17032 missing\n",
      "  ‚Ä¢ 2004rikisreikningurheild_parsed_clean.csv: 4726 missing\n",
      "  ‚Ä¢ Rikisreikningur-arid-2015-Arsreikningar-rikisadila_parsed_normalized.csv: 16791 missing\n",
      "  ‚Ä¢ all_years_parsed_normalized.csv: 325780 missing\n",
      "  ‚Ä¢ Rikisreikningur-arid-2013-Arsreikningur-Rikisadila_parsed_clean.csv: 17032 missing\n",
      "  ‚Ä¢ rikisreikningur2012_parsed_clean.csv: 5563 missing\n",
      "  ‚Ä¢ Rikisreikningur-arid-2013,-Heildaryfirlit---Rafraen-undirritun_parsed_clean.csv: 6245 missing\n",
      "  ‚Ä¢ Rikisreikningur-2011-arsreikningar-rikiisadila_parsed_normalized.csv: 17325 missing\n",
      "  ‚Ä¢ RR-2008-R_parsed_clean.csv: 5424 missing\n",
      "  ‚Ä¢ Rikisreikningur-2019_parsed_normalized.csv: 6898 missing\n",
      "  ‚Ä¢ fb_300904_ahj_parsed_clean.csv: 32 missing\n",
      "  ‚Ä¢ Rikisreikningur-arid-2013,-Heildaryfirlit---Rafraen-undirritun_parsed_normalized.csv: 6245 missing\n",
      "  ‚Ä¢ Rikisreikn-02_parsed_normalized.csv: 4979 missing\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Scan normalized CSVs for missing normalized categories\n",
    "missing_counts = {}\n",
    "for file in os.listdir(normalized_dir):\n",
    "    if not file.endswith(\".csv\"):\n",
    "        continue\n",
    "    df = pd.read_csv(os.path.join(normalized_dir, file))\n",
    "    if \"normalized_category\" not in df.columns:\n",
    "        print(f\"‚ö†Ô∏è {file} has no normalized_category column!\")\n",
    "        continue\n",
    "    missing = df[\"normalized_category\"].isna().sum()\n",
    "    if missing > 0:\n",
    "        missing_counts[file] = missing\n",
    "\n",
    "if missing_counts:\n",
    "    print(\"‚ö†Ô∏è Missing normalized categories found:\")\n",
    "    for f, count in missing_counts.items():\n",
    "        print(f\"  ‚Ä¢ {f}: {count} missing\")\n",
    "else:\n",
    "    print(\"‚úÖ All normalized CSVs are fully mapped and consistent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00a52528-f59f-4fde-b54f-bb68e16d389a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/mappings_cleaned.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m unmapped_output = \u001b[33m\"\u001b[39m\u001b[33mdata/unmapped_after_propagation.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# === LOAD EXISTING MAPPINGS ===\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m mappings_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmappings_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m mapping_dict = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mzip\u001b[39m(\n\u001b[32m     13\u001b[39m         mappings_df[\u001b[33m\"\u001b[39m\u001b[33mMinistry\u001b[39m\u001b[33m\"\u001b[39m].str.strip(),\n\u001b[32m     14\u001b[39m         mappings_df[\u001b[33m\"\u001b[39m\u001b[33mCategory\u001b[39m\u001b[33m\"\u001b[39m].str.strip()\n\u001b[32m     15\u001b[39m     )\n\u001b[32m     16\u001b[39m )\n\u001b[32m     18\u001b[39m updated_files = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/iceland-spending-ai/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/iceland-spending-ai/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/iceland-spending-ai/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/iceland-spending-ai/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/iceland-spending-ai/venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/mappings_cleaned.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# === CONFIG ===\n",
    "\n",
    "# === LOAD EXISTING MAPPINGS ===\n",
    "mappings_df = pd.read_csv(mappings_file)\n",
    "mapping_dict = dict(\n",
    "    zip(\n",
    "        mappings_df[\"Ministry\"].str.strip(),\n",
    "        mappings_df[\"Category\"].str.strip()\n",
    "    )\n",
    ")\n",
    "\n",
    "updated_files = []\n",
    "unmapped_counts = {}\n",
    "global_unmapped = set()\n",
    "\n",
    "print(\"üîÑ Propagating normalized categories into structured CSVs...\")\n",
    "\n",
    "# === ITERATE THROUGH STRUCTURED CSVs ===\n",
    "for fname in sorted(os.listdir(structured_dir)):\n",
    "    if not fname.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(structured_dir, fname)\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Skip CSVs missing a Ministry column\n",
    "    if \"Ministry\" not in df.columns:\n",
    "        continue\n",
    "\n",
    "    # Map normalized categories\n",
    "    df[\"normalized_category\"] = df[\"Ministry\"].str.strip().map(mapping_dict)\n",
    "\n",
    "    # Find missing ministries for this file\n",
    "    missing_mask = df[\"normalized_category\"].isna()\n",
    "    missing_count = missing_mask.sum()\n",
    "\n",
    "    if missing_count > 0:\n",
    "        unmapped_counts[fname] = missing_count\n",
    "        global_unmapped.update(df.loc[missing_mask, \"Ministry\"].dropna().unique())\n",
    "\n",
    "    # Save the updated CSV back to the structured folder\n",
    "    df.to_csv(path, index=False)\n",
    "    updated_files.append(fname)\n",
    "\n",
    "# === EXPORT ALL GLOBAL UNMAPPED MINISTRIES ===\n",
    "if global_unmapped:\n",
    "    unmapped_df = pd.DataFrame(sorted(global_unmapped), columns=[\"Ministry\"])\n",
    "    unmapped_df.to_csv(unmapped_output, index=False)\n",
    "    print(f\"\\nüìù Unmapped ministries exported to: {unmapped_output}\")\n",
    "\n",
    "    # === APPEND UNMAPPED MINISTRIES INTO MAPPINGS FILE ===\n",
    "    existing_ministries = set(mappings_df[\"Ministry\"].str.strip())\n",
    "    new_entries = unmapped_df[~unmapped_df[\"Ministry\"].str.strip().isin(existing_ministries)]\n",
    "    if not new_entries.empty:\n",
    "        new_entries = new_entries.assign(Category=\"Misc/Missing\")\n",
    "        mappings_df = pd.concat([mappings_df, new_entries], ignore_index=True)\n",
    "        mappings_df.to_csv(mappings_file, index=False)\n",
    "        print(f\"‚ûï Added {len(new_entries)} new placeholder mappings to: {mappings_file}\")\n",
    "\n",
    "# === SUMMARY ===\n",
    "print(\"\\n=== PROPAGATION SUMMARY ===\")\n",
    "print(f\"‚úÖ Updated {len(updated_files)} structured CSVs\")\n",
    "\n",
    "if unmapped_counts:\n",
    "    print(\"‚ö†Ô∏è Files still missing categories:\")\n",
    "    for fname, count in unmapped_counts.items():\n",
    "        print(f\"   ‚Ä¢ {fname}: {count} missing\")\n",
    "    print(f\"\\nüìù Full list of unmapped ministries saved to: {unmapped_output}\")\n",
    "    print(\"‚ö° Next step: Update these new entries in mappings_cleaned.csv with real categories.\")\n",
    "else:\n",
    "    print(\"üéâ All normalized categories successfully propagated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd045b0b-c798-4ddd-b61c-480a2ade0155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ampersand/iceland-spending-ai\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/home/ampersand/iceland-spending-ai\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ed41038-3d84-4054-9616-63d1a42f6404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "497df6c8-de1e-4634-9fca-5465c817a91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Using Ollama for 36 unmapped ministries...\n",
      "‚úÖ Automatic classification completed.\n",
      "üíæ Updated mappings saved to: /home/ampersand/iceland-spending-ai/data/mappings_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIG ===\n",
    "root = Path('/home/ampersand/iceland-spending-ai')\n",
    "unmapped_file = data_dir / \"unmapped_after_propagation.csv\"\n",
    "\n",
    "# === LOAD EXISTING MAPPINGS ===\n",
    "mappings_df = pd.read_csv(mappings_file)\n",
    "existing_categories = sorted(mappings_df[\"Category\"].dropna().unique())\n",
    "\n",
    "# === LOAD UNMAPPED MINISTRIES ===\n",
    "if unmapped_file.exists():\n",
    "    unmapped_df = pd.read_csv(unmapped_file)\n",
    "    # Collect ministries from normalized outputs if available\n",
    "    all_unmapped = unmapped_df.get(\"Unmapped_Ministry\", unmapped_df.iloc[:, 0])\n",
    "    unmapped_list = sorted(set(all_unmapped.dropna().str.strip()))\n",
    "else:\n",
    "    print(\"‚úÖ No unmapped ministries found.\")\n",
    "    unmapped_list = []\n",
    "\n",
    "# === CHECK FOR OLLAMA ===\n",
    "def ollama_available():\n",
    "    try:\n",
    "        result = subprocess.run([\"ollama\", \"--version\"], capture_output=True)\n",
    "        return result.returncode == 0\n",
    "    except FileNotFoundError:\n",
    "        return False\n",
    "\n",
    "has_ollama = ollama_available()\n",
    "\n",
    "# === FUNCTION TO CLASSIFY MINISTRIES ===\n",
    "def classify_with_ollama(ministry, categories):\n",
    "    prompt = f\"\"\"\n",
    "    Given these categories: {', '.join(categories)},\n",
    "    choose the single most appropriate category for the Icelandic ministry or institution below.\n",
    "    Ministry/Institution: \"{ministry}\"\n",
    "    Answer ONLY with the category name from the provided list.\n",
    "    \"\"\"\n",
    "    result = subprocess.run(\n",
    "        [\"ollama\", \"run\", \"llama3\", \"--json\"],\n",
    "        input=prompt.encode(),\n",
    "        capture_output=True\n",
    "    )\n",
    "    try:\n",
    "        output = json.loads(result.stdout.decode())[\"response\"].strip()\n",
    "    except Exception:\n",
    "        output = \"Misc/Missing\"\n",
    "    return output\n",
    "\n",
    "# === AUTO-SUGGEST MAPPINGS ===\n",
    "suggested_mappings = {}\n",
    "\n",
    "if has_ollama and unmapped_list:\n",
    "    print(f\"ü§ñ Using Ollama for {len(unmapped_list)} unmapped ministries...\")\n",
    "    for ministry in unmapped_list:\n",
    "        suggested_category = classify_with_ollama(ministry, existing_categories)\n",
    "        suggested_mappings[ministry] = suggested_category\n",
    "    print(\"‚úÖ Automatic classification completed.\")\n",
    "elif unmapped_list:\n",
    "    print(f\"‚ö†Ô∏è Ollama not found. {len(unmapped_list)} ministries remain unmapped.\")\n",
    "else:\n",
    "    print(\"‚úÖ Nothing to classify.\")\n",
    "\n",
    "# === UPDATE MAPPINGS FILE ===\n",
    "if suggested_mappings:\n",
    "    # Create a DataFrame of new mappings\n",
    "    new_df = pd.DataFrame(\n",
    "        list(suggested_mappings.items()), columns=[\"Ministry\", \"Category\"]\n",
    "    )\n",
    "    # Append and drop duplicates just in case\n",
    "    mappings_df = pd.concat([mappings_df, new_df], ignore_index=True)\n",
    "    mappings_df.drop_duplicates(subset=[\"Ministry\"], inplace=True)\n",
    "    mappings_df.to_csv(mappings_file, index=False)\n",
    "    print(f\"üíæ Updated mappings saved to: {mappings_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424db487-d3e1-438a-964b-523d771e6406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
